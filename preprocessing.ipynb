{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "import os\n",
    "\n",
    "def load_ephys(ephys_file: str, num_samples: int = -1, start = 0, stop = 0, nchannels: int = 16, dtype = np.uint32, order = 'F') -> np.array:\n",
    "    '''\n",
    "    Load and reshape binary electrophysiology data into a NumPy array.\n",
    "\n",
    "    This function is designed to read binary files containing electrophysiology \n",
    "    (ephys) data. It loads the specified number of samples from the file and \n",
    "    reshapes them into a 2D NumPy array, where each row represents a channel.\n",
    "\n",
    "    Parameters:\n",
    "    ephys_file (str): Path to the binary file containing electrophysiology data.\n",
    "    num_samples (int): Number of samples to read from the file.\n",
    "    nchannels (int, optional): Number of channels in the ephys data. Defaults to 16.\n",
    "\n",
    "    Returns:\n",
    "    np.array: A 2D NumPy array of the electrophysiology data, reshaped into\n",
    "              (nchannels, number_of_samples_per_channel).\n",
    "    '''\n",
    "  \n",
    "    # reading in binary data\n",
    "    num_samples = num_samples * nchannels\n",
    "    ephys_bin = np.fromfile(ephys_file, dtype=dtype, count = num_samples)\n",
    "    \n",
    "    # ensuring equal samples from each channel\n",
    "    num_complete_sets = len(ephys_bin) // nchannels\n",
    "    ephys_bin = ephys_bin[:num_complete_sets * nchannels]\n",
    "\n",
    "    # reshape 1d array into nchannels x num_samples NumPy array\n",
    "    ephys_data = np.reshape(ephys_bin, (nchannels, -1), order=order)\n",
    "\n",
    "    # removing start seconds from beggining, and stop from end of signal; default is 0\n",
    "    start = start * 30000\n",
    "    stop = stop * 30000\n",
    "\n",
    "    if stop == 0:\n",
    "        ephys = ephys_data[:, start:]\n",
    "    else:\n",
    "        ephys = ephys_data[:, start: -stop]\n",
    "\n",
    "    return ephys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the data directory and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"C:\\Users\\smearlab\\clickbait-ephys\"\n",
    "save_dir = r\"C:\\Users\\smearlab\\clickbait-ephys\\preprocessed_data\"\n",
    "mice = ['6000', '6001', '6002', '6003']\n",
    "skip_sessions = [0,1,2,3,4,5,6,7]\n",
    "session_offset = 3\n",
    "gain = 0.1949999928474426\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "open_ephys_dir = os.path.join(data_dir, \"open-ephys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Extracting OpenEphys Data (Sniff, Ephys, TTLs) and Restructuring the Data\n",
    "\n",
    "The script processes raw OpenEphys data, extracting relevant signals (LFP, MUA, sniff, TTLs) and saving them in a structured format. The preprocessed data will be stored in the `preprocessed_data` directory with the following structure:\n",
    "\n",
    "\n",
    "```\n",
    "preprocessed_data\n",
    "‚îú‚îÄ‚îÄ <animal_id>\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ <session_id>\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lfp.npy\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mua.npy\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sniff.npy\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ttls.npy\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### üóÇÔ∏è **Data Descriptions:**\n",
    "\n",
    "- **`lfp.npy`** *(Local Field Potential)*  \n",
    "  - **Description:** Represents the slow oscillatory activity of the brain.  \n",
    "  - **Processing:** Low-pass filtered at **300 Hz** to capture relevant neural dynamics.\n",
    "\n",
    "- **`mua.npy`** *(Multi-Unit Activity)*  \n",
    "  - **Description:** Captures high-frequency spiking activity from multiple neurons.  \n",
    "  - **Processing:** Band-pass filtered between **300 Hz and 6 kHz** and **median common average referenced** within regions to reduce noise.\n",
    "\n",
    "- **`sniff.npy`** *(Sniff Data)*  \n",
    "  - **Description:** Raw sniffing signal representing respiratory behavior.  \n",
    "  - **Processing:** Extracted directly from the raw data without additional filtering.\n",
    "\n",
    "- **`ttls.npy`** *(TTL Pulses)*  \n",
    "  - **Description:** Raw TTL (Transistor-Transistor Logic) pulses used as event markers.  \n",
    "  - **Processing:** Saved in raw format to preserve precise event timing.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session: 2025-02-03_14-25-38_6000\n",
      "Skipping session: 2025-02-03_14-25-38_6000\n",
      "Processing session: 2025-02-04_14-04-31_6000\n",
      "Skipping session: 2025-02-04_14-04-31_6000\n",
      "Processing session: 2025-02-05_14-03-34_6000\n",
      "Skipping session: 2025-02-05_14-03-34_6000\n",
      "Processing session: 2025-02-06_16-02-02_6000\n",
      "Skipping session: 2025-02-06_16-02-02_6000\n",
      "Processing session: 2025-02-07_14-11-26_6000\n",
      "Skipping session: 2025-02-07_14-11-26_6000\n",
      "Processing session: 2025-02-08_13-31-21_6000\n",
      "Skipping session: 2025-02-08_13-31-21_6000\n",
      "Processing session: 2025-02-09_12-26-57_6000\n",
      "Skipping session: 2025-02-09_12-26-57_6000\n",
      "Processing session: 2025-02-10_14-50-57_6000\n",
      "Skipping session: 2025-02-10_14-50-57_6000\n",
      "Processing session: 2025-02-11_10-30-34_6000\n",
      "Data path: C:\\Users\\smearlab\\clickbait-ephys\\open-ephys\\2025-02-11_10-30-34_6000\\Record Node 104\\experiment1\\recording1\\continuous\\Acquisition_Board-102.Rhythm Data\\continuous.dat\n",
      "Loaded data successfully for 2025-02-11_10-30-34_6000\n",
      "\n",
      "Processing session: 2025-02-12_14-31-08_6000\n",
      "Data path: C:\\Users\\smearlab\\clickbait-ephys\\open-ephys\\2025-02-12_14-31-08_6000\\Record Node 104\\experiment1\\recording1\\continuous\\Acquisition_Board-102.Rhythm Data\\continuous.dat\n",
      "Loaded data successfully for 2025-02-12_14-31-08_6000\n",
      "\n",
      "Processing session: 2025-02-13_10-29-05_6000\n",
      "Data path: C:\\Users\\smearlab\\clickbait-ephys\\open-ephys\\2025-02-13_10-29-05_6000\\Record Node 104\\experiment1\\recording1\\continuous\\Acquisition_Board-102.Rhythm Data\\continuous.dat\n",
      "Loaded data successfully for 2025-02-13_10-29-05_6000\n",
      "\n",
      "Processing session: 2025-02-14_12-13-13_6000\n",
      "Data path: C:\\Users\\smearlab\\clickbait-ephys\\open-ephys\\2025-02-14_12-13-13_6000\\Record Node 104\\experiment1\\recording1\\continuous\\Acquisition_Board-102.Rhythm Data\\continuous.dat\n"
     ]
    }
   ],
   "source": [
    "# List all files in the open-ephys directory\n",
    "all_files = os.listdir(open_ephys_dir)\n",
    "\n",
    "# Loop through each mouse\n",
    "for mouse in mice:\n",
    "    # Filter files related to the current mouse\n",
    "    mouse_sessions = [f.strip() for f in all_files if mouse in f]\n",
    "\n",
    "    # Process each session for the current mouse\n",
    "    for session in tqdm(mouse_sessions):\n",
    "        print(f\"Processing session: {session}\")\n",
    "\n",
    "        # Extract date and session number\n",
    "        date = session[:10]\n",
    "        try:\n",
    "            session_num = int(date[-2:]) - session_offset\n",
    "        except ValueError:\n",
    "            print(f\"Invalid date format in session: {session}\")\n",
    "            continue\n",
    "\n",
    "        if session_num in skip_sessions:\n",
    "            print(f\"Skipping session: {session}\")\n",
    "            continue\n",
    "\n",
    "        # Build the path to the data directory\n",
    "        session_path = os.path.join(open_ephys_dir, session)\n",
    "\n",
    "        # Check if the session directory exists\n",
    "        if not os.path.isdir(session_path):\n",
    "            print(f\"Session directory not found: {session_path}\")\n",
    "            continue\n",
    "\n",
    "        # Get the first subdirectory (assumed to be the \"Record Node\" folder)\n",
    "        try:\n",
    "            record_node = os.listdir(session_path)[0]\n",
    "        except IndexError:\n",
    "            print(f\"No files found in session: {session_path}\")\n",
    "            continue\n",
    "\n",
    "        # Build the path to the continuous data directory\n",
    "        continuous_dir = os.path.join(session_path, record_node, 'experiment1', 'recording1', 'continuous')\n",
    "\n",
    "        # Check if the continuous directory exists\n",
    "        if not os.path.isdir(continuous_dir):\n",
    "            print(f\"Continuous directory not found: {continuous_dir}\")\n",
    "            continue\n",
    "\n",
    "        # Get the acquisition board folder\n",
    "        try:\n",
    "            acquisition_board = os.listdir(continuous_dir)[0]\n",
    "        except IndexError:\n",
    "            print(f\"No acquisition board folder found in: {continuous_dir}\")\n",
    "            continue\n",
    "\n",
    "        # Final path to the continuous.dat file\n",
    "        data_path = os.path.join(continuous_dir, acquisition_board, 'continuous.dat')\n",
    "        print(f\"Data path: {data_path}\")\n",
    "\n",
    "        # Load the electrophysiological data\n",
    "        if os.path.exists(data_path):\n",
    "            try:\n",
    "\n",
    "                # Loading the data\n",
    "                data = load_ephys(data_path, nchannels=40, dtype=np.int16, order='F')\n",
    "\n",
    "                # Making the data directory\n",
    "                data_dir = os.path.join(save_dir, mouse, str(session_num))\n",
    "                os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "                # Extracting the ephys, sniff, and ttl timeseries\n",
    "                ephys = (data[:32, :] * gain).astype(np.float64)\n",
    "                sniff = data[-1, :]\n",
    "                ttls = data[-2, :]\n",
    "\n",
    "                # lowpass filtering the ephys data to get the LFP\n",
    "                sos = signal.butter(4, 300, 'lowpass', fs=30000, output='sos')\n",
    "                lfps = signal.sosfiltfilt(sos, ephys)\n",
    "\n",
    "                # bandpass filtering the ephys data to get the MUA\n",
    "                sos = signal.butter(4, [300, 6000], 'bandpass', fs=30000, output='sos')\n",
    "                mua = signal.sosfiltfilt(sos, ephys)\n",
    "\n",
    "                # median common average referencing the multiunit activity\n",
    "                mua[:16, :] -= np.median(mua[:16, :], axis=0)\n",
    "                mua[16:, :] -= np.median(mua[16:, :], axis=0)\n",
    "\n",
    "                # converting back to int16\n",
    "                lfps = lfps.astype(np.int16)\n",
    "                mua = mua.astype(np.int16)\n",
    "                sniff = sniff.astype(np.int16)\n",
    "                ttls = ttls.astype(np.int16)\n",
    "\n",
    "                # Ensuring files do not already exist\n",
    "                if os.path.exists(os.path.join(data_dir, 'lfp.npy')) or \\\n",
    "                   os.path.exists(os.path.join(data_dir, 'mua.npy')) or \\\n",
    "                   os.path.exists(os.path.join(data_dir, 'sniff.npy')) or \\\n",
    "                   os.path.exists(os.path.join(data_dir, 'ttls.npy')):\n",
    "                    print(f\"Files already exist for {session}, skipping...\")\n",
    "                    continue\n",
    "\n",
    "                # Saving the data as binary files\n",
    "                np.save(os.path.join(data_dir, 'lfp.npy'), lfps)\n",
    "                np.save(os.path.join(data_dir, 'mua.npy'), mua)\n",
    "                np.save(os.path.join(data_dir, 'sniff.npy'), sniff)\n",
    "                np.save(os.path.join(data_dir, 'ttls.npy'), ttls)\n",
    "\n",
    "                print(f\"Loaded data successfully for {session}\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading data from {data_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"Data path not found: {data_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
